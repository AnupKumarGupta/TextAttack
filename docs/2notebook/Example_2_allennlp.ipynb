{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[TextAttack] Model Example: AllenNLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPVBc5ndpFIX"
      },
      "source": [
        "# TextAttack & AllenNLP \n",
        "\n",
        "This is an example of testing adversarial attacks from TextAttack on pretrained models provided by AllenNLP. \n",
        "\n",
        "In a few lines of code, we load a sentiment analysis model trained on the Stanford Sentiment Treebank and configure it with a TextAttack model wrapper. Then, we initialize the TextBugger attack and run the attack on a few samples from the SST-2 train set.\n",
        "\n",
        "For more information on AllenNLP pre-trained models: https://docs.allennlp.org/v1.0.0rc3/tutorials/getting_started/using_pretrained_models/\n",
        "\n",
        "For more information about the TextBugger attack: https://arxiv.org/abs/1812.05271"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyPMGcz0qLfK"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QData/TextAttack/blob/master/docs/2notebook/Example_2_allennlp.ipynb)\n",
        "\n",
        "[![View Source on GitHub](https://img.shields.io/badge/github-view%20source-black.svg)](https://github.com/QData/TextAttack/blob/master/docs/2notebook/Example_2_allennlp.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_br6Xvsif9SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224cc851-0e9d-4454-931c-64bd3b7af400"
      },
      "source": [
        "from allennlp.predictors import Predictor\n",
        "import allennlp_models.classification\n",
        "\n",
        "import textattack\n",
        "\n",
        "class AllenNLPModel(textattack.models.wrappers.ModelWrapper):\n",
        "    def __init__(self):\n",
        "        self.model = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\")\n",
        "\n",
        "    def __call__(self, text_input_list):\n",
        "        outputs = []\n",
        "        for text_input in text_input_list:\n",
        "            outputs.append(self.model.predict(sentence=text_input))\n",
        "        # For each output, outputs['logits'] contains the logits where\n",
        "        # index 0 corresponds to the positive and index 1 corresponds \n",
        "        # to the negative score. We reverse the outputs (by reverse slicing,\n",
        "        # [::-1]) so that negative comes first and positive comes second.\n",
        "        return [output['logits'][::-1] for output in outputs]\n",
        "\n",
        "model_wrapper = AllenNLPModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDRWI5Psb85g",
        "outputId": "db7f8f94-0d78-45ea-a7ac-e12167c28365"
      },
      "source": [
        "from textattack.datasets import HuggingFaceDataset\n",
        "from textattack.attack_recipes import TextBuggerLi2018\n",
        "from textattack.attacker import Attacker\n",
        "\n",
        "\n",
        "dataset = HuggingFaceDataset(\"glue\", \"sst2\", \"train\")\n",
        "attack = TextBuggerLi2018.build(model_wrapper)\n",
        "\n",
        "attacker = Attacker(attack, dataset)\n",
        "attacker.attack_dataset()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
            "Exception ignored in: <bound method CapturableResourceDeleter.__del__ of <tensorflow.python.training.tracking.tracking.CapturableResourceDeleter object at 0x7f586ddcc908>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py\", line 208, in __del__\n",
            "    self._destroy_resource()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
            "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
            "    *args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
            "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
            "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py\", line 253, in restored_function_body\n",
            "    return _call_concrete_function(function, inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py\", line 75, in _call_concrete_function\n",
            "    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\", line 116, in _call_flat\n",
            "    cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1932, in _call_flat\n",
            "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 589, in call\n",
            "    executor_type=executor_type)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\", line 1206, in partitioned_call\n",
            "    f.add_to_graph(graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 505, in add_to_graph\n",
            "    g._add_function(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3396, in _add_function\n",
            "    gradient)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null\n",
            "textattack: Unknown if model of class <class 'allennlp.predictors.text_classifier.TextClassifierPredictor'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapRandomCharacterInsertion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (1): WordSwapRandomCharacterDeletion(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (2): WordSwapNeighboringCharacterSwap(\n",
            "        (random_one):  True\n",
            "      )\n",
            "    (3): WordSwapHomoglyphSwap\n",
            "    (4): WordSwapEmbedding(\n",
            "        (max_candidates):  5\n",
            "        (embedding):  WordEmbedding\n",
            "      )\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.8\n",
            "        (window_size):  inf\n",
            "        (skip_text_shorter_than_window):  False\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): RepeatModification\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "WARNING:tensorflow:5 out of the last 17 calls to <function recreate_function.<locals>.restored_function_body at 0x7f5861596b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5 out of the last 17 calls to <function recreate_function.<locals>.restored_function_body at 0x7f5861596b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[Succeeded / Failed / Total] 1 / 1 / 2:  40%|████      | 2/5 [00:00<00:00,  4.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[91mNegative (95%)\u001b[0m --> \u001b[92mPositive (93%)\u001b[0m\n",
            "\n",
            "\u001b[91mhide\u001b[0m new secretions from the parental units \n",
            "\n",
            "\u001b[92mconcealing\u001b[0m new secretions from the parental units \n",
            "\n",
            "\n",
            "--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (96%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "contains no wit , only labored gags \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Succeeded / Failed / Total] 1 / 2 / 4:  80%|████████  | 4/5 [00:00<00:00,  4.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "that loves its characters and communicates something rather beautiful about human nature \n",
            "\n",
            "\n",
            "--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (82%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "remains utterly satisfied to remain the same throughout \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Succeeded / Failed / Total] 2 / 2 / 5: 100%|██████████| 5/5 [00:01<00:00,  3.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (98%)\u001b[0m --> \u001b[92mPositive (52%)\u001b[0m\n",
            "\n",
            "on the \u001b[91mworst\u001b[0m \u001b[91mrevenge-of-the-nerds\u001b[0m clichés the filmmakers could \u001b[91mdredge\u001b[0m up \n",
            "\n",
            "on the \u001b[92mpire\u001b[0m \u001b[92mreveng-of-the-nerds\u001b[0m clichés the filmmakers could \u001b[92mdragging\u001b[0m up \n",
            "\n",
            "\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 2      |\n",
            "| Number of failed attacks:     | 2      |\n",
            "| Number of skipped attacks:    | 1      |\n",
            "| Original accuracy:            | 80.0%  |\n",
            "| Accuracy under attack:        | 40.0%  |\n",
            "| Attack success rate:          | 50.0%  |\n",
            "| Average perturbed word %:     | 22.14% |\n",
            "| Average num. words per input: | 8.6    |\n",
            "| Avg num queries:              | 25.5   |\n",
            "+-------------------------------+--------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbbWHEv0b3s4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}