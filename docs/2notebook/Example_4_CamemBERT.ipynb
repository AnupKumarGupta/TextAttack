{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "build_central"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Example_4_CamemBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koVcufVBD9uv"
      },
      "source": [
        "# Multi-language attacks\n",
        "\n",
        "TextAttack's four-component framework makes it trivial to run attacks in other languages. In this tutorial, we:\n",
        "\n",
        "- Create a model wrapper around Transformers [pipelines](https://huggingface.co/transformers/main_classes/pipelines.html) \n",
        "- Initialize a pre-trained [CamemBERT](https://camembert-model.fr/) model for sentiment classification\n",
        "- Load the AlloCiné movie review sentiment classification dataset (from [`datasets`](https://github.com/huggingface/datasets/))\n",
        "- Load the `pwws` recipe, but use French synonyms from multilingual WordNet (instead of English synonyms)\n",
        "- Run an adversarial attack on a French language model\n",
        "\n",
        "Voilà!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abd2C3zJD9u4"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QData/TextAttack/blob/master/docs/2notebook/Example_4_CamemBERT.ipynb)\n",
        "\n",
        "[![View Source on GitHub](https://img.shields.io/badge/github-view%20source-black.svg)](https://github.com/QData/TextAttack/blob/master/docs/2notebook/Example_4_CamemBERT.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fnSUl8ND9u5"
      },
      "source": [
        "from textattack.attack_recipes import PWWSRen2019\n",
        "from textattack.datasets import HuggingFaceDataset\n",
        "from textattack.models.wrappers import ModelWrapper\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
        "from textattack import Attacker\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Quiet TensorFlow.\n",
        "import os\n",
        "if \"TF_CPP_MIN_LOG_LEVEL\" not in os.environ:\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "\n",
        "class HuggingFaceSentimentAnalysisPipelineWrapper(ModelWrapper):\n",
        "    \"\"\" Transformers sentiment analysis pipeline returns a list of responses\n",
        "        like \n",
        "        \n",
        "            [{'label': 'POSITIVE', 'score': 0.7817379832267761}]\n",
        "            \n",
        "        We need to convert that to a format TextAttack understands, like\n",
        "        \n",
        "            [[0.218262017, 0.7817379832267761]\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = model#pipeline = pipeline\n",
        "    def __call__(self, text_inputs):\n",
        "        raw_outputs = self.model(text_inputs)\n",
        "        outputs = []\n",
        "        for output in raw_outputs:\n",
        "            score = output['score']\n",
        "            if output['label'] == 'POSITIVE':\n",
        "                outputs.append([1-score, score])\n",
        "            else:\n",
        "                outputs.append([score, 1-score])\n",
        "        return np.array(outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i2WPtwO9D9u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5e8fab-1047-417d-c90c-b9238b2886a4"
      },
      "source": [
        "# Create the model: a French sentiment analysis model.\n",
        "# see https://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\")\n",
        "pipeline = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
        "\n",
        "model_wrapper = HuggingFaceSentimentAnalysisPipelineWrapper(pipeline)\n",
        "\n",
        "# Create the recipe: PWWS uses a WordNet transformation.\n",
        "recipe = PWWSRen2019.build(model_wrapper)\n",
        "#\n",
        "# WordNet defaults to english. Set the default language to French ('fra')\n",
        "#\n",
        "# See \"Building a free French wordnet from multilingual resources\", \n",
        "# E. L. R. A. (ELRA) (ed.), \n",
        "# Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).\n",
        "recipe.transformation.language = 'fra'\n",
        "\n",
        "dataset = HuggingFaceDataset('allocine', split='test')\n",
        "\n",
        "attacker = Attacker(recipe, dataset)\n",
        "attacker.attack_dataset()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
            "\n",
            "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n",
            "textattack: Unknown if model of class <class 'transformers.pipelines.text_classification.TextClassificationPipeline'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Reusing dataset allocine_dataset (/root/.cache/huggingface/datasets/allocine_dataset/allocine/1.0.0/bbee2ebb45a067891973b91ebdd40a93598d1e2dd5710b6714cdc2cd81d0ed65)\n",
            "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mallocine\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  weighted-saliency\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapWordNet\n",
            "  (constraints): \n",
            "    (0): RepeatModification\n",
            "    (1): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [00:52<03:30, 52.67s/it]\u001b[A\n",
            "[Succeeded / Failed / Total] 0 / 1 / 1:  20%|██        | 1/5 [00:52<03:30, 52.68s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Magnifique épopée, une belle histoire, touchante avec des acteurs qui interprètent très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), le genre de film qui se savoure en famille! :)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Succeeded / Failed / Total] 0 / 1 / 1:  40%|████      | 2/5 [03:11<04:47, 95.76s/it]\u001b[A\n",
            "[Succeeded / Failed / Total] 1 / 1 / 2:  40%|████      | 2/5 [03:11<04:47, 95.76s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (94%)\u001b[0m --> \u001b[92mPositive (91%)\u001b[0m\n",
            "\n",
            "Je n'ai pas aimé mais pourtant je lui mets \u001b[91m2\u001b[0m étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.\n",
            "\n",
            "Je n'ai pas aimé mais pourtant je lui mets \u001b[92m4\u001b[0m étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Succeeded / Failed / Total] 1 / 1 / 2:  60%|██████    | 3/5 [03:15<02:10, 65.23s/it]\u001b[A\n",
            "[Succeeded / Failed / Total] 2 / 1 / 3:  60%|██████    | 3/5 [03:15<02:10, 65.24s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (85%)\u001b[0m --> \u001b[91mNegative (91%)\u001b[0m\n",
            "\n",
            "Un \u001b[92mdessin\u001b[0m animé qui brille par sa féerie et ses chansons.\n",
            "\n",
            "Un \u001b[91mbrouillon\u001b[0m animé qui brille par sa féerie et ses chansons.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Succeeded / Failed / Total] 2 / 1 / 3:  80%|████████  | 4/5 [03:49<00:57, 57.43s/it]\u001b[A\n",
            "[Succeeded / Failed / Total] 3 / 1 / 4:  80%|████████  | 4/5 [03:49<00:57, 57.43s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (80%)\u001b[0m\n",
            "\n",
            "\u001b[91mSi\u001b[0m c'est là le renouveau du cinéma français, c'est tout \u001b[91mde\u001b[0m même foutrement chiant. \u001b[91mSi\u001b[0m l'objet est \u001b[91mtrès\u001b[0m stylisé et la tension palpable, le film paraît \u001b[91mplutôt\u001b[0m \u001b[91mcreux\u001b[0m.\n",
            "\n",
            "\u001b[92maussi\u001b[0m c'est là le renouveau du cinéma français, c'est tout \u001b[92mabolir\u001b[0m même foutrement chiant. \u001b[92mtellement\u001b[0m l'objet est \u001b[92mprodigieusement\u001b[0m stylisé et la tension palpable, le film paraît \u001b[92mpeu\u001b[0m \u001b[92mtrou\u001b[0m.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Succeeded / Failed / Total] 3 / 1 / 4: 100%|██████████| 5/5 [04:09<00:00, 49.95s/it]\u001b[A\n",
            "[Succeeded / Failed / Total] 3 / 2 / 5: 100%|██████████| 5/5 [04:09<00:00, 49.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "Et pourtant on s’en Doutait !Second volet très mauvais, sans fraîcheur et particulièrement lourdingue. Quel dommage.\n",
            "\n",
            "\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 3      |\n",
            "| Number of failed attacks:     | 2      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 40.0%  |\n",
            "| Attack success rate:          | 60.0%  |\n",
            "| Average perturbed word %:     | 10.72% |\n",
            "| Average num. words per input: | 29.4   |\n",
            "| Avg num queries:              | 324.6  |\n",
            "+-------------------------------+--------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6voq7KqEuBt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}